Background Information
======
  In the field of genomics and bioinformatics, open reading frames (ORFs) refer to a section of sequence in the mRNA code that the ribosome reads and creates an amino acid chain from. This amino acid chain then folds into a functional protien that is used by the organism to perform required cellular work and functions. ORFs are usually defined by a start codon (ATG/AUG), a varying length of sequence, and a stop codon (UAA/TAA, UAG/TAG, UGA/TGA). However, finding these sequences by hand is a very tedious process that is incredibly difficult with how long and variable mRNA code can be. Another challenge that scientists face is that RNA can be encoded from 6 reading frames from one sequence of code due to the triplicate pattern that codons follow (three reading frames on the forward strand, three on the reverse strand). With these two issues combined, the manual discovery of ORFs is near impossible. 

  Thanks to the continuously evolving field of bioinformatics, the need for manual exploration of genetic code is no longer necessary. There are many coding languages that now exist that have the capability to be written to scan through genetic sequences and pull out sequences of interest. For the project being outlined in this document, Python code was used to create and ORF Finder. A user can specify a sequence from an organism of interest and the code will search through each reading frame (both on the forward and reverse strand) and search for a start codon and record the sequence until a stop codon is hit. From there, each ORF is locally BLASTed against a database of the users specification, and the results are stored in a termporary file. This file is then used to build a GFF file for the user to easily read through the detected ORFS. The methods of how this code runs is deatailed below. 
##
##
Methods
======
![image](https://user-images.githubusercontent.com/83464534/166949877-c85dc343-ccd3-415f-92f6-6d526a015cff.png) [^1].
[^1]: flowchart outlining the input and flow of the written code

  To run the code that was written, an anaconda environment was activated to import and run python modules need to allow the code to function. To start, the argparse module was used to accept three required positional arguments. The first argument asks for the input files name that contains the sequence you wish to use. This file must be in FASTA format and can contain more than one sequence from the same organism. The second argument is the database URL that they wish to locally BLAST against. Lastly, the user must input what they wishe to name the output GFF file. this can be whatever the user desires as long as it follows the filename formatting required in the commandline. For testing the code, the Escherichia coli str. K-12 whole genome FASTA file was downloaded from the [NCBI database](https://www.ncbi.nlm.nih.gov/nuccore/U00096.2?report=fasta) and named EColi.fasta for easy accesibility. The output file was named Ecoli.gff, and the NCBI bacterial database was downloaded from [this link](https://ftp.ncbi.nlm.nih.gov/refseq/release/bacteria/bacteria.1.1.genomic.fna.gz).
  
  Once the arguments have been accepted by the user, the specified FASTA file is opened and read using the os module. the function named fileparse() then removes all headers from the sequence and then are parsed into a list style format, where each header and sequence are added to a major list as  tuple( (header, sequence) ). The headers are stored with the sequence in this fashion in case the user wishes to access these headers at a later time for data breakdown. This list is then passed to the next function called orffinder(). This function takes the sequences from the list and systematicaly goes through each reading frame and breaks the sequence into its individual codons for easier parsing. Once the reading frame is broken down, the sequence is scanned for the start codon (ATG). When it hits a start codon, it starts adding each codon associated with the reading frame to a list. Once it hits a stop codon, that list is then added to an overarching list, and the process repeats itself until all six reading frames have been parsed. 
    
  The next step in this process is to filter and BLAST these ORFs against a local database. In order to BLAST these sequences, they need to be in FASTA file format. To accomplish this, the list of lists that contains the ORFs are passed to a function called filterorfs(), which sequentially goes through each string of codons and determines the length. This helps the code filter out any sequences that are statistically too short or too long to be a workable ORF in the organism. The smallest a sequence can be to be considered functional is ~ 100 amino acids (300 bases), and the cuttoff length for this code is ~ 350 amino acids (1050 bases). All sequences not in this range are discarded by the code, while sequences within this range are added to a file with a unique header for each. this FASTA file is then passed to the BLAST function.
    
   To preform a local BLAST, the subprocess module is imported and run to pull the database online to the directory the user is working with using the wget command, and then it is further decompressed using the gzip command. This then opens and sets up the database within the directory where the code is running so that the sequences do not need to be exported from the server and manually BLASTed.  Next, the FASTA file from the previous function is passed into the blastn command. The output file for this BLAST is saved in [format 6](https://www.metagenomics.wiki/tools/blast/blastn-output-format-6), which is a format tailored to help easily parse out the BLAST results to be formatted into GFF files.
   
   The final function for the code utilizes the csv module to write a GFF formated document from the BLAST results. For each return entry in the BLAST file, only the top result for each ORF is used, since this has the highest likelihood to match to the organism of interest. From there, a tab delimited entry is written for each orf, which includes the sequence name, the database that peformed the search (in this case, it would be NCBI), what kind of feature it is (in this case, all ORFs), start and stop position of the sequence, the score of the sequence, if the sequence is on the forward or reverse strand, frame, and finally additional information that blast provides about the sequence. Once all ORF entries are witten to the file, the file is closed and named whatever the user specified in the beginning arguments. The code then cleans up all database files and unnecessary intermediate files from the users directory using the os module and leaves only the original input fasta file and the output GFF file.
##
##
Results
======
![Screenshot (36)](https://user-images.githubusercontent.com/83464534/168375381-4da40f4b-d44e-4ad9-9598-2271cb8fdb40.png) [^2].
[^2]: Output from code outlined in this document and recodred in github

When examining the output GFF file of the code, the results align with what a proper GFF file should look like. All fields are filled out with the correct information, and all results have unique start and stop positions (i.e. all ORFs are unique and not nested within each other). When looking at the size of the file, there are 4334 lines, with 4309 lines containing E. coli sequences. When looking up how many calculated E. coli ORFs exist, there are roughly 4333 known ORFs in the whole genome. When calculating the persentage of accuracy from these numbers, this indicates that the program has a 99% success rate in finding known ORFs in a well documented organism. 

To ensure that each function is running without issue, text prompts are printed to the screen in between function calling. While running this program, every single test prompt showed up with no errors in between. With all of these confirming results, this leads to the assumption that the code works as intended, with the output being accurate and statistically and bioligically accurate. 



